{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92cf9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "SEED = 1013\n",
    "np.random.seed(SEED)\n",
    "#nltk.download('stopwords')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, twitter_samples \n",
    "from stance_utils import *\n",
    "#from utils import *\n",
    "#from parameters import *\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dropout,Concatenate,Dense, Embedding, LSTM, SpatialDropout1D, Flatten, GRU, Bidirectional, Conv1D, Input,MaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stemmer = PorterStemmer()\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "stopwords_english = stopwords.words('english')\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9250cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'FAVOR': np.array([1, 0, 0]), 'NONE': np.array([0, 1, 0]), 'AGAINST': np.array([0, 0, 1])}\n",
    "classes_ = np.array(['FAVOR', 'NONE', 'AGAINST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3dad654",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = '/data/parush/stance_mohammed/train.txt'\n",
    "test_data_file = '/data/parush/stance_mohammed/test.txt'\n",
    "TARGETS = [ 'Atheism','Climate Change is a Real Concern', 'Feminist Movement','Hillary Clinton', 'Legalization of Abortion' ]\n",
    "\n",
    "\n",
    "# train_data_file = '/data/parush/SomasundaranWiebe-politicalDebates/train.txt'\n",
    "# test_data_file = '/data/parush/SomasundaranWiebe-politicalDebates/test.txt'\n",
    "# TARGETS = ['god','healthcare','guns','gayRights','abortion', 'creation']\n",
    "\n",
    "\n",
    "# train_data_file = '/data/parush/Data_MPCHI/train.txt'\n",
    "# test_data_file = '/data/parush/Data_MPCHI/test.txt'\n",
    "# TARGETS = ['Are E-Cigarettes safe?','Does MMR Vaccine lead to autism in children?',\n",
    "#       'Does Sunlight exposure lead to skin cancer?','Does Vitamin C prevent common cold?',\n",
    "#       'Should women take HRT post-menopause?']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd466a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f54f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test():\n",
    "    \n",
    "    sentence_maxlen = 0\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    \n",
    "    with open(train_data_file, 'r') as trainfile:\n",
    "        for line in trainfile:\n",
    "            \n",
    "            line = line.replace('#SemST', '').strip()\n",
    "            line = line.split('\\t')\n",
    "            \n",
    "            #if line[0].strip() != 'ID' and line[1].strip() == t:\n",
    "            if line[0].strip() != 'ID':\n",
    "                tweet = line[2]\n",
    "                tweet = process_tweet(tweet)\n",
    "                if len(tweet) > sentence_maxlen:\n",
    "                    sentence_maxlen = len(tweet)\n",
    "                x_train.append(tweet)\n",
    "                y_train.append(classes[line[3].strip()])\n",
    "                               \n",
    "    \n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    with open(test_data_file, 'r') as testfile:\n",
    "        for line in testfile:\n",
    "            line = line.replace('#SemST', '').strip()\n",
    "            line = line.split('\\t')\n",
    "        \n",
    "\n",
    "            #if line[0] != 'ID' and line[1] == t:\n",
    "            if line[0] != 'ID':\n",
    "                tweet = line[2]\n",
    "                tweet = process_tweet(tweet)\n",
    "                if len(tweet) > sentence_maxlen:\n",
    "                    sentence_maxlen = len(tweet)\n",
    "                x_test.append(tweet)\n",
    "                y_test.append(classes[line[3].strip()])\n",
    "\n",
    "\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test, sentence_maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f854b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1718156",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, sentence_maxlen = train_and_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4885da02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocab are 6497\n"
     ]
    }
   ],
   "source": [
    "vocabulary = build_vocab(x_train)\n",
    "vocab_size = len(vocabulary)\n",
    "print(\"Total words in vocab are\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5282b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings_weights = get_embeddings('wikipedia',100,vocabulary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c2f7094",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    tweet_tensor = tweet_to_tensor(x_train[i], vocabulary)\n",
    "    if len(tweet_tensor) < sentence_maxlen:\n",
    "        diff = sentence_maxlen - len(tweet_tensor)\n",
    "        n_pad = [0]*diff\n",
    "        tweet_tensor = tweet_tensor + n_pad\n",
    "    x_train[i] = tweet_tensor\n",
    "for i in range(len(x_test)):\n",
    "    tweet_tensor = tweet_to_tensor(x_test[i], vocabulary)\n",
    "    if len(tweet_tensor) < sentence_maxlen:\n",
    "        diff = sentence_maxlen - len(tweet_tensor)\n",
    "        n_pad = [0]*diff\n",
    "        tweet_tensor = tweet_tensor + n_pad\n",
    "    x_test[i] = tweet_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e7fe4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "y_test = np.asarray(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "148a8654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2914"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "180da236",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "def biLSTM():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(embeddings_weights.shape[0], embeddings_weights.shape[1], weights=[embeddings_weights]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64,return_sequences=True,dropout=0.3))\n",
    "    model.add(Bidirectional(LSTM(64,dropout=0.3)))\n",
    "    #model.add(Flatten())\n",
    "    #add a dropout here\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes,activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def biLSTMCNN():\n",
    "    inputs = Input(shape=(sentence_maxlen,))\n",
    "    embedded_inputs = Embedding(embeddings_weights.shape[0], embeddings_weights.shape[1], weights=[embeddings_weights])(inputs)\n",
    "    embedded_inputs = Dropout(0.2)(embedded_inputs)\n",
    "    lstm = Bidirectional(LSTM(64,return_sequences=True,dropout=0.3))(embedded_inputs)\n",
    "    convs = []\n",
    "    for each_filter_size in [3,4,5]:\n",
    "        #print(rnn.shape)\n",
    "        each_conv = Conv1D(100, each_filter_size, activation='relu')(lstm)\n",
    "        each_conv = MaxPooling1D(sentence_maxlen-each_filter_size+1)(each_conv)\n",
    "        each_conv = Flatten()(each_conv)\n",
    "        #print(each_conv.shape)\n",
    "        convs.append(each_conv)\n",
    "        \n",
    "    output = Concatenate()(convs)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = (Dense(3,activation='softmax'))(output)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy']) \n",
    "    return model\n",
    "\n",
    "def biGRU():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(embeddings_weights.shape[0], embeddings_weights.shape[1], weights=[embeddings_weights]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(GRU(64,return_sequences=True,dropout=0.3)))\n",
    "    model.add(Bidirectional(GRU(64,dropout=0.3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def biGRUCNN():\n",
    "    inputs = Input(shape=(sentence_maxlen,))\n",
    "    embedded_inputs = Embedding(embeddings_weights.shape[0], embeddings_weights.shape[1], weights=[embeddings_weights])(inputs)\n",
    "    embedded_inputs = Dropout(0.2)(embedded_inputs)\n",
    "    rnn = Bidirectional(GRU(64,return_sequences=True,dropout=0.3))(embedded_inputs)\n",
    "    convs = []\n",
    "    for each_filter_size in [3,4,5]:\n",
    "        #print(rnn.shape)\n",
    "        each_conv = Conv1D(100, each_filter_size, activation='relu')(rnn)\n",
    "        each_conv = MaxPooling1D(sentence_maxlen-each_filter_size+1)(each_conv)\n",
    "        each_conv = Flatten()(each_conv)\n",
    "        #print(each_conv.shape)\n",
    "        convs.append(each_conv)\n",
    "        \n",
    "    output = Concatenate()(convs)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = (Dense(3,activation='softmax'))(output)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9437abbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-30 18:13:49.349371: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/cuda/cuda-11.2/lib64:/opt/rh/devtoolset-8/root/usr/lib64:/opt/rh/devtoolset-8/root/usr/lib:/opt/rh/devtoolset-8/root/usr/lib64/dyninst:/opt/rh/devtoolset-8/root/usr/lib/dyninst:/opt/rh/devtoolset-8/root/usr/lib64:/opt/rh/devtoolset-8/root/usr/lib:/usr/include/slurm/\n",
      "2021-08-30 18:13:49.349421: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-08-30 18:13:49.349459: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (gaivi.cse.usf.edu): /proc/driver/nvidia/version does not exist\n",
      "2021-08-30 18:13:49.349760: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 20, 100)      649700      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 20, 100)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 20, 128)      84480       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 18, 100)      38500       bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 17, 100)      51300       bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 16, 100)      64100       bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 1, 100)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 100)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1, 100)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100)          0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 100)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 100)          0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 300)          0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            903         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 888,983\n",
      "Trainable params: 888,983\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = biLSTMCNN()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52c8ef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-30 18:13:55.797218: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-30 18:13:55.797852: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2399910000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "146/146 [==============================] - 5s 15ms/step - loss: 1.0290 - accuracy: 0.4869\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.9152 - accuracy: 0.5701\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.7903 - accuracy: 0.6461\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.6275 - accuracy: 0.7490\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.4669 - accuracy: 0.8164\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.3628 - accuracy: 0.8541\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.2644 - accuracy: 0.8958\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.2043 - accuracy: 0.9266\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.1526 - accuracy: 0.9421\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.1535 - accuracy: 0.9477\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.1013 - accuracy: 0.9678\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.1061 - accuracy: 0.9610\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0798 - accuracy: 0.9751\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0723 - accuracy: 0.9781\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0580 - accuracy: 0.9816\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0743 - accuracy: 0.9760\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0601 - accuracy: 0.9798\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0565 - accuracy: 0.9816\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0387 - accuracy: 0.9888\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0454 - accuracy: 0.9876\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0361 - accuracy: 0.9871\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0318 - accuracy: 0.9871\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0377 - accuracy: 0.9884\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0309 - accuracy: 0.9888\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0326 - accuracy: 0.9871\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0312 - accuracy: 0.9901\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0223 - accuracy: 0.9918\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0340 - accuracy: 0.9893\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0267 - accuracy: 0.9901\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0168 - accuracy: 0.9944\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0283 - accuracy: 0.9901\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0184 - accuracy: 0.9927\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0160 - accuracy: 0.9944\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0156 - accuracy: 0.9940\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0124 - accuracy: 0.9961\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0144 - accuracy: 0.9957\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0344 - accuracy: 0.9914\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0193 - accuracy: 0.9940\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0180 - accuracy: 0.9944\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0156 - accuracy: 0.9953\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0108 - accuracy: 0.9961\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0078 - accuracy: 0.9979\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0067 - accuracy: 0.9974\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0198 - accuracy: 0.9936\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0113 - accuracy: 0.9949\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0288 - accuracy: 0.9918\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0188 - accuracy: 0.9949\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0163 - accuracy: 0.9914\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0191 - accuracy: 0.9931\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0195 - accuracy: 0.9949\n",
      "accuracy: 58.49%\n",
      "Epoch 1/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.5301 - accuracy: 0.8687\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.2135 - accuracy: 0.9326\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.1555 - accuracy: 0.9477\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0874 - accuracy: 0.9734\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0602 - accuracy: 0.9768\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0480 - accuracy: 0.9824\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0437 - accuracy: 0.9850\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0299 - accuracy: 0.9876\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0269 - accuracy: 0.9906\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0231 - accuracy: 0.9944\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0169 - accuracy: 0.9957\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0265 - accuracy: 0.9914\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0196 - accuracy: 0.9949\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0159 - accuracy: 0.9940\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0181 - accuracy: 0.9944\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0129 - accuracy: 0.9961\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0079 - accuracy: 0.9970\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0089 - accuracy: 0.9970\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0123 - accuracy: 0.9966\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0151 - accuracy: 0.9953\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0097 - accuracy: 0.9961\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0078 - accuracy: 0.9970\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0077 - accuracy: 0.9979\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0116 - accuracy: 0.9957\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0122 - accuracy: 0.9961\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0093 - accuracy: 0.9953\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0168 - accuracy: 0.9949\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0113 - accuracy: 0.9966\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0114 - accuracy: 0.9961\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0076 - accuracy: 0.9966\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0054 - accuracy: 0.9974\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0087 - accuracy: 0.9983\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0111 - accuracy: 0.9961\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0135 - accuracy: 0.9949\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0329 - accuracy: 0.9936\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0073 - accuracy: 0.9974\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0046 - accuracy: 0.9983\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0090 - accuracy: 0.9966\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0088 - accuracy: 0.9979\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0081 - accuracy: 0.9979\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0100 - accuracy: 0.9979\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0104 - accuracy: 0.9979\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0098 - accuracy: 0.9966\n",
      "accuracy: 96.40%\n",
      "Epoch 1/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0991 - accuracy: 0.9790\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0217 - accuracy: 0.9931\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0110 - accuracy: 0.9966\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0148 - accuracy: 0.9961\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0163 - accuracy: 0.9953\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0115 - accuracy: 0.9957\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0103 - accuracy: 0.9953\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0056 - accuracy: 0.9974\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0053 - accuracy: 0.9974\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0053 - accuracy: 0.9979\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0116 - accuracy: 0.9970\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0056 - accuracy: 0.9966\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0108 - accuracy: 0.9957\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0055 - accuracy: 0.9979\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0099 - accuracy: 0.9953\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0126 - accuracy: 0.9944\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0112 - accuracy: 0.9970\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0129 - accuracy: 0.9953\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0103 - accuracy: 0.9979\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0051 - accuracy: 0.9974\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0036 - accuracy: 0.9983\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0100 - accuracy: 0.9970\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0040 - accuracy: 0.9974\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0142 - accuracy: 0.9949\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0093 - accuracy: 0.9979\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0058 - accuracy: 0.9983\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0065 - accuracy: 0.9970\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0167 - accuracy: 0.9970\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0039 - accuracy: 0.9983\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0036 - accuracy: 0.9979\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0037 - accuracy: 0.9974\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0036 - accuracy: 0.9987\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0078 - accuracy: 0.9979\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0127 - accuracy: 0.9949\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0034 - accuracy: 0.9983\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0026 - accuracy: 0.9987\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0026 - accuracy: 0.9987\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0025 - accuracy: 0.9983\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0034 - accuracy: 0.9983\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0062 - accuracy: 0.9974\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0061 - accuracy: 0.9974\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0105 - accuracy: 0.9974\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0063 - accuracy: 0.9983\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0025 - accuracy: 0.9979\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0032 - accuracy: 0.9987\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0216 - accuracy: 0.9974\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0040 - accuracy: 0.9983\n",
      "accuracy: 99.66%\n",
      "Epoch 1/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0260 - accuracy: 0.9931\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0101 - accuracy: 0.9983\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0056 - accuracy: 0.9983\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0094 - accuracy: 0.9974\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0032 - accuracy: 0.9991\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 6.1885e-04 - accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 2.8279e-04 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0043 - accuracy: 0.9979\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0083 - accuracy: 0.9974\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0094 - accuracy: 0.9979\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0069 - accuracy: 0.9987\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0057 - accuracy: 0.9983\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0050 - accuracy: 0.9979\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 0.0086 - accuracy: 0.9970\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0101 - accuracy: 0.9991\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0059 - accuracy: 0.9974\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0087 - accuracy: 0.9987\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0089 - accuracy: 0.9987\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0043 - accuracy: 0.9996\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 5.2043e-04 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0057 - accuracy: 0.9983\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0040 - accuracy: 0.9983\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 7.3254e-04 - accuracy: 0.9996\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0020 - accuracy: 0.9991\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 9.4767e-04 - accuracy: 0.9996\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0021 - accuracy: 0.9991\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0032 - accuracy: 0.9991\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0168 - accuracy: 0.9970\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0116 - accuracy: 0.9979\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 3.2930e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0042 - accuracy: 0.9991\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 3.6518e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 8.0411e-05 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 5.7280e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 6.3622e-04 - accuracy: 0.9996\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 0.0058 - accuracy: 0.9991\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 3s 17ms/step - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "accuracy: 99.66%\n",
      "Epoch 1/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 0.0353 - accuracy: 0.9966\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0064 - accuracy: 0.9983\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 0.0115 - accuracy: 0.9970\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 0.0041 - accuracy: 0.9983\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 0.0046 - accuracy: 0.9983\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 0.0103 - accuracy: 0.9970\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 0.0055 - accuracy: 0.9983\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0085 - accuracy: 0.9970\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 2s 16ms/step - loss: 0.0129 - accuracy: 0.9979\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 0.0034 - accuracy: 0.9983\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0138 - accuracy: 0.9979\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 0.0018 - accuracy: 0.9991\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0040 - accuracy: 0.9991\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 0.0053 - accuracy: 0.9987\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 0.0031 - accuracy: 0.9983\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0021 - accuracy: 0.9991\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0017 - accuracy: 0.9991\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0099 - accuracy: 0.9970\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0041 - accuracy: 0.9974\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0022 - accuracy: 0.9991\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0047 - accuracy: 0.9970\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0110 - accuracy: 0.9966\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0033 - accuracy: 0.9979\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 0.0038 - accuracy: 0.9983\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 0.0034 - accuracy: 0.9987\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0020 - accuracy: 0.9991\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 0.0033 - accuracy: 0.9983\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 0.0051 - accuracy: 0.9974\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0023 - accuracy: 0.9987\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 0.0064 - accuracy: 0.9983\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0053 - accuracy: 0.9979\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 0.0045 - accuracy: 0.9979\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 0.0035 - accuracy: 0.9983\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0070 - accuracy: 0.9974\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0023 - accuracy: 0.9983\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0024 - accuracy: 0.9991\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 3s 20ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0139 - accuracy: 0.9966\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0141 - accuracy: 0.9979\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0019 - accuracy: 0.9991\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0018 - accuracy: 0.9991\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 0.0028 - accuracy: 0.9983\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 2s 15ms/step - loss: 0.0021 - accuracy: 0.9987\n",
      "accuracy: 100.00%\n",
      "90.84% (+/- 16.23%)\n",
      "For:                precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4573    0.5461    0.4978       304\n",
      "           1     0.3653    0.4304    0.3952       230\n",
      "           2     0.7378    0.6336    0.6817       715\n",
      "\n",
      "   micro avg     0.5753    0.5749    0.5751      1249\n",
      "   macro avg     0.5201    0.5367    0.5249      1249\n",
      "weighted avg     0.6009    0.5749    0.5842      1249\n",
      " samples avg     0.5749    0.5749    0.5749      1249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p/parush/.conda/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "cvscores = []\n",
    "\n",
    "for train, val in kfold.split(x_train, classes_[y_train.argmax(1)]):\n",
    "    model.fit(x_train[train], y_train[train], epochs = 50, batch_size = 16, verbose=1)\n",
    "    scores = model.evaluate(x_train[val], y_train[val], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "\n",
    "y_pred = np.round(model.predict(x_test))\n",
    "\n",
    "print(\"For: \",classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d11628",
   "metadata": {},
   "outputs": [],
   "source": [
    "For:                precision    recall  f1-score   support\n",
    "\n",
    "           0     0.4413    0.5197    0.4773       304\n",
    "           1     0.3815    0.4130    0.3967       230\n",
    "           2     0.7314    0.6476    0.6869       715\n",
    "\n",
    "   micro avg     0.5774    0.5733    0.5753      1249\n",
    "   macro avg     0.5181    0.5268    0.5203      1249\n",
    "weighted avg     0.5964    0.5733    0.5825      1249\n",
    " samples avg     0.5733    0.5733    0.5733      1249"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
