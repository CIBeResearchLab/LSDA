{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47c95f5-c1ba-4a45-bf43-917fd3c30b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "SEED = 1013\n",
    "np.random.seed(SEED)\n",
    "#nltk.download('stopwords')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, twitter_samples \n",
    "from stance_utils import *\n",
    "#from parameters import *\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "#from tensorflow.keras.layers import Dropout,Concatenate,Dense, Embedding, SpatialDropout1D, Flatten, GRU, Bidirectional, Conv1D,MaxPooling1D\n",
    "\n",
    "from tensorflow.keras.layers import RNN, Dropout,Concatenate,Dense, Embedding,LSTMCell, LSTM, SpatialDropout1D, Flatten, GRU, Bidirectional, Conv1D, Input,MaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stemmer = PorterStemmer()\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "stopwords_english = stopwords.words('english')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras.backend as K\n",
    "from keras.layers import Lambda\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef1eb2ac-3c04-4226-ad5f-ae132b6fae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'FAVOR': np.array([1, 0, 0]), 'AGAINST': np.array([0, 1, 0]), 'NONE': np.array([0, 0, 1])}\n",
    "classes_ = np.array(['FAVOR', 'AGAINST', 'NONE'])\n",
    "models = ['bicond', 'biLSTM', 'biLSTMCNN', 'biGRU', 'biGRUCNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc10ac3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "setting = 'in' #'in' or 'cross'\n",
    "units = 60\n",
    "model = 'biLSTM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65230d80-7c1f-453d-a66c-c5043bf88588",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file_m = '/data/parush/stance_mohammed/train.txt'\n",
    "test_data_file_m = '/data/parush/stance_mohammed/test.txt'\n",
    "TARGETS_m = [ 'Atheism','Climate Change is a Real Concern', 'Feminist Movement','Hillary Clinton', 'Legalization of Abortion' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f08aad6-d353-4f23-82d6-034c785aaff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(train_file, test_file, target):\n",
    "    \n",
    "    sentence_maxlen = 0\n",
    "    target_maxlen = 0\n",
    "    x_s_token = []\n",
    "    x_t_token = []\n",
    "    y_train = []\n",
    "\n",
    "    \n",
    "    with open(train_file, 'r') as trainfile:\n",
    "        for line in trainfile: \n",
    "            line = line.replace('#SemST', '').strip()\n",
    "            line = line.split('\\t')\n",
    "            \n",
    "            \n",
    "            if line[0].strip() != 'ID' and target in line[1].strip():\n",
    "                tweet = line[2]\n",
    "                tweet = process_tweet(tweet)\n",
    "                if len(tweet) > sentence_maxlen:\n",
    "                    sentence_maxlen = len(tweet)\n",
    "                x_s_token.append(tweet)\n",
    "                target_ = line[1].strip().lower().split()\n",
    "                if len(target_) > target_maxlen:\n",
    "                    target_maxlen = len(target_)\n",
    "                x_t_token.append(target_)\n",
    "                y_train.append(classes[line[3].strip()])\n",
    "    \n",
    "\n",
    "                               \n",
    "    \n",
    "    x_s_test_token = []\n",
    "    x_t_test_token = []\n",
    "    y_test = []\n",
    "    with open(test_file, 'r') as testfile:\n",
    "        for line in testfile:\n",
    "            line = line.replace('#SemST', '').strip()\n",
    "            line = line.split('\\t')\n",
    "        \n",
    "\n",
    "            \n",
    "            if line[0] != 'ID' and target in line[1].strip():\n",
    "                tweet = line[2]\n",
    "                tweet = process_tweet(tweet)\n",
    "                if len(tweet) > sentence_maxlen:\n",
    "                    sentence_maxlen = len(tweet)\n",
    "                x_s_test_token.append(tweet)\n",
    "                target_ = line[1].strip().lower().split()\n",
    "                if len(target_) > target_maxlen:\n",
    "                    target_maxlen = len(target_)\n",
    "                x_t_test_token.append(target_)\n",
    "                y_test.append(classes[line[3].strip()])\n",
    "\n",
    "\n",
    "    \n",
    "    return x_s_token, x_t_token, x_s_test_token, x_t_test_token, y_train, y_test, sentence_maxlen, target_maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08ddd7e6-fbc1-4815-9486-7ec4fd80ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setting == 'in':\n",
    "    x_s_token, x_t_token, x_s_test_token, x_t_test_token, y_train, y_test, sentence_maxlen, target_maxlen  = train_and_test(train_data_file_m, test_data_file_m, TARGETS_m[2])\n",
    "if setting == 'cross':\n",
    "    x_s_token, x_t_token, _, _, y_train, _, sentence_maxlen, target_maxlen  = train_and_test(train_data_file_m, test_data_file_m, TARGETS_m[2])\n",
    "    _, _, x_s_test_token, x_t_test_token, _, y_test, _, _  = train_and_test(train_data_file_m, test_data_file_m, TARGETS_m[4])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5668309-53e2-466c-b413-0df0aac2eecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocab are 2349\n"
     ]
    }
   ],
   "source": [
    "vocabulary = build_vocab(x_s_token + x_t_token )\n",
    "vocab_size = len(vocabulary)\n",
    "print(\"Total words in vocab are\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "946d2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == 'bicond':\n",
    "    y_train = np.asarray(y_train)\n",
    "    _,balance = divmod(len(y_train),batch_size)\n",
    "    print(_,balance)\n",
    "    print(len(y_train))\n",
    "    n_splits=len(y_train)//balance\n",
    "    print(n_splits)\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    for train_index, test_index in kfold.split(x_s_token, classes_[y_train.argmax(1)]):\n",
    "        test_index = test_index\n",
    "        break\n",
    "    y_train = list(y_train)\n",
    "    test_index = list(test_index)\n",
    "    for i in test_index:\n",
    "        x_s_token.append(x_s_token[i])\n",
    "        y_train.append(y_train[i])\n",
    "        x_t_token.append(x_t_token[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8215158-4421-4a4c-88c0-b60598dbf465",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s = [tweet_to_tensor(each_s,vocabulary) for each_s in x_s_token]\n",
    "x_s = pad_sequences(x_s, maxlen = sentence_maxlen, padding = 'post')\n",
    "x_s_test = [tweet_to_tensor(each_s,vocabulary) for each_s in x_s_test_token]\n",
    "x_s_test = pad_sequences(x_s_test, maxlen = sentence_maxlen, padding = 'post')\n",
    "\n",
    "x_t = [tweet_to_tensor(each_s,vocabulary) for each_s in x_t_token]\n",
    "x_t = pad_sequences(x_t, maxlen = sentence_maxlen, padding = 'post')\n",
    "x_t_test = [tweet_to_tensor(each_s,vocabulary) for each_s in x_t_test_token]\n",
    "x_t_test = pad_sequences(x_t_test, maxlen = sentence_maxlen, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0decbff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b255d44e-796b-498e-9736-ecf96a732ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "x_s = x_s[shuffle_indices]\n",
    "x_t = x_t[shuffle_indices]\n",
    "y_train = np.asarray(y_train)\n",
    "y_train = y_train[shuffle_indices]\n",
    "y_test = np.asarray(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef1fa903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = get_embeddings('twitter',100,vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609d376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf8efe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2da81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "num_classes = 3\n",
    "\n",
    "\n",
    "def bicond(units,inputs,opt, embedding_matrix, x_t):\n",
    "    embedded_inputs = tf.nn.embedding_lookup(embedding_matrix, x_t)\n",
    "    print(embedded_inputs.shape)\n",
    "    inputs = embedded_inputs[:batch_size]\n",
    "    \n",
    "    h_0 = tf.convert_to_tensor(np.zeros([batch_size, units]).astype(np.float32))\n",
    "    c_0 = tf.convert_to_tensor(np.zeros([batch_size, units]).astype(np.float32))\n",
    "    start_state = [h_0, c_0]\n",
    "    lstm = LSTM(units, return_sequences=True, return_state=True)\n",
    "    fw_output, fw_h_0, fw_c_0 = lstm(inputs,initial_state = [h_0, c_0])\n",
    "    bw_output, bw_h_0, bw_c_0 = lstm(inputs[::-1],initial_state = [h_0, c_0]) # feeding data backwords\n",
    "    \n",
    "    inputs2 = Input(shape=(sentence_maxlen), name = 'Input')\n",
    "    embedded_inputs = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix], name = 'Embedding')(inputs2)\n",
    "    lstm = LSTM(units,activation='tanh',dropout=0.1,name = 'lstm')(embedded_inputs, initial_state = [h_0, fw_c_0])\n",
    "    b_lstm = LSTM(units,activation='tanh',dropout=0.1, go_backwards = True,name = 'back_lstm')(embedded_inputs, initial_state = [h_0, bw_c_0])\n",
    "    cond_out = []\n",
    "    cond_out.append(lstm)\n",
    "    cond_out.append(b_lstm)\n",
    "    concat_output = Concatenate()(cond_out)\n",
    "    flat = Flatten(name = 'Flatten')(concat_output)\n",
    "    output = (Dense(3,activation='softmax',name = 'Dense'))(flat)\n",
    "    model = Model(inputs=inputs2, outputs=output)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics = ['accuracy'])    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def biLSTM():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64,return_sequences=True,dropout=0.3))\n",
    "    model.add(Bidirectional(LSTM(64,dropout=0.3)))\n",
    "    #model.add(Flatten())\n",
    "    #add a dropout here\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes,activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def biLSTMCNN():\n",
    "    inputs = Input(shape=(sentence_maxlen,))\n",
    "    embedded_inputs = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix])(inputs)\n",
    "    embedded_inputs = Dropout(0.2)(embedded_inputs)\n",
    "    lstm = Bidirectional(LSTM(64,return_sequences=True,dropout=0.3))(embedded_inputs)\n",
    "    convs = []\n",
    "    for each_filter_size in [3,4,5]:\n",
    "        #print(rnn.shape)\n",
    "        each_conv = Conv1D(100, each_filter_size, activation='relu')(lstm)\n",
    "        each_conv = MaxPooling1D(sentence_maxlen-each_filter_size+1)(each_conv)\n",
    "        each_conv = Flatten()(each_conv)\n",
    "        #print(each_conv.shape)\n",
    "        convs.append(each_conv)\n",
    "        \n",
    "    output = Concatenate()(convs)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = (Dense(3,activation='softmax'))(output)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy']) \n",
    "    return model\n",
    "\n",
    "def biGRU():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(GRU(64,return_sequences=True,dropout=0.3)))\n",
    "    model.add(Bidirectional(GRU(64,dropout=0.3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def biGRUCNN():\n",
    "    inputs = Input(shape=(sentence_maxlen,))\n",
    "    embedded_inputs = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1], weights=[embedding_matrix])(inputs)\n",
    "    embedded_inputs = Dropout(0.2)(embedded_inputs)\n",
    "    rnn = Bidirectional(GRU(64,return_sequences=True,dropout=0.3))(embedded_inputs)\n",
    "    convs = []\n",
    "    for each_filter_size in [3,4,5]:\n",
    "        #print(rnn.shape)\n",
    "        each_conv = Conv1D(100, each_filter_size, activation='relu')(rnn)\n",
    "        each_conv = MaxPooling1D(sentence_maxlen-each_filter_size+1)(each_conv)\n",
    "        each_conv = Flatten()(each_conv)\n",
    "        #print(each_conv.shape)\n",
    "        convs.append(each_conv)\n",
    "        \n",
    "    output = Concatenate()(convs)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = (Dense(3,activation='softmax'))(output)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])    \n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8242e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = biLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fce7612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         234900    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 64)          42240     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 343,575\n",
      "Trainable params: 343,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eabf7a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "34/34 [==============================] - 5s 18ms/step - loss: 1.0369 - accuracy: 0.4689\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.9621 - accuracy: 0.5009\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.8950 - accuracy: 0.5480\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.8099 - accuracy: 0.6215\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.7191 - accuracy: 0.6723\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.5984 - accuracy: 0.7608\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.5639 - accuracy: 0.7589\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.4789 - accuracy: 0.8343\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.3732 - accuracy: 0.8606\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.3319 - accuracy: 0.8814\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.2952 - accuracy: 0.8851\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.2802 - accuracy: 0.8945\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.2243 - accuracy: 0.9209\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.1359 - accuracy: 0.9492\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.1600 - accuracy: 0.9322\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.2000 - accuracy: 0.9303\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.1034 - accuracy: 0.9661\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.1221 - accuracy: 0.9529\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.1383 - accuracy: 0.9492\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0961 - accuracy: 0.9755\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0561 - accuracy: 0.9774\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.1295 - accuracy: 0.9567\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0472 - accuracy: 0.9887\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0802 - accuracy: 0.9736\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0346 - accuracy: 0.9925\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0608 - accuracy: 0.9812\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0676 - accuracy: 0.9793\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0568 - accuracy: 0.9793\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0593 - accuracy: 0.9812\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0448 - accuracy: 0.9849\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0480 - accuracy: 0.9831\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0806 - accuracy: 0.9755\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0333 - accuracy: 0.9887\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0185 - accuracy: 0.9944\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0603 - accuracy: 0.9831\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0387 - accuracy: 0.9831\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0334 - accuracy: 0.9925\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0466 - accuracy: 0.9887\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0215 - accuracy: 0.9944\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0389 - accuracy: 0.9906\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0735 - accuracy: 0.9793\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0119 - accuracy: 0.9981\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0200 - accuracy: 0.9906\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0354 - accuracy: 0.9849\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0231 - accuracy: 0.9925\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0318 - accuracy: 0.9906\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0313 - accuracy: 0.9925\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0236 - accuracy: 0.9887\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0227 - accuracy: 0.9925\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0444 - accuracy: 0.9887\n",
      "accuracy: 56.39%\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.4309 - accuracy: 0.8701\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.2697 - accuracy: 0.9171\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.2043 - accuracy: 0.9209\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.1383 - accuracy: 0.9586\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.1413 - accuracy: 0.9586\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0630 - accuracy: 0.9812\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0569 - accuracy: 0.9774\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0537 - accuracy: 0.9774\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0532 - accuracy: 0.9849\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0318 - accuracy: 0.9849\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0370 - accuracy: 0.9906\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0232 - accuracy: 0.9944\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0389 - accuracy: 0.9849\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0226 - accuracy: 0.9906\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0104 - accuracy: 0.9962\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0409 - accuracy: 0.9849\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0161 - accuracy: 0.9962\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0249 - accuracy: 0.9925\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0157 - accuracy: 0.9981\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0070 - accuracy: 0.9962\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0221 - accuracy: 0.9962\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0208 - accuracy: 0.9962\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0349 - accuracy: 0.9849\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0282 - accuracy: 0.9925\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0304 - accuracy: 0.9944\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0353 - accuracy: 0.9831\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0267 - accuracy: 0.9944\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0129 - accuracy: 0.9962\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0296 - accuracy: 0.9887\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0122 - accuracy: 0.9944\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0182 - accuracy: 0.9944\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0109 - accuracy: 0.9962\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0465 - accuracy: 0.9793\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0073 - accuracy: 0.9962\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0360 - accuracy: 0.9887\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0285 - accuracy: 0.9925\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0146 - accuracy: 0.9925\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0162 - accuracy: 0.9981\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0106 - accuracy: 0.9962\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0105 - accuracy: 0.9981\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 5.6062e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.9943e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0155 - accuracy: 0.9944\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0099 - accuracy: 0.9981\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0091 - accuracy: 0.9962\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0047 - accuracy: 0.9981\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0030 - accuracy: 0.9981\n",
      "accuracy: 100.00%\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0212 - accuracy: 0.9906\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0548 - accuracy: 0.9831\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0109 - accuracy: 0.9962\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0156 - accuracy: 0.9981\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0340 - accuracy: 0.9906\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0203 - accuracy: 0.9981\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0209 - accuracy: 0.9962\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0095 - accuracy: 0.9962\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0038 - accuracy: 0.9981\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0096 - accuracy: 0.9981\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0297 - accuracy: 0.9944\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0143 - accuracy: 0.9962\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0052 - accuracy: 0.9962\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0076 - accuracy: 0.9981\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0031 - accuracy: 0.9981\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0024 - accuracy: 0.9981\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0187 - accuracy: 0.9944\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0764 - accuracy: 0.9793\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0146 - accuracy: 0.9925\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0070 - accuracy: 0.9981\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0054 - accuracy: 0.9981\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0021 - accuracy: 0.9981\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0143 - accuracy: 0.9981\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0158 - accuracy: 0.9981\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0070 - accuracy: 0.9962\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0025 - accuracy: 0.9981\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0157 - accuracy: 0.9944\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0062 - accuracy: 0.9981\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0047 - accuracy: 0.9981\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 7.9325e-04 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0120 - accuracy: 0.9981\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 5.5824e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0096 - accuracy: 0.9981\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0156 - accuracy: 0.9981\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0038 - accuracy: 0.9981\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 4.0010e-04 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "accuracy: 100.00%\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0039 - accuracy: 0.9981\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 2.7864e-04 - accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.7422e-04 - accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 2.2455e-04 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.5496e-04 - accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 4.2550e-04 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0033 - accuracy: 0.9981\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0040 - accuracy: 0.9981\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0020 - accuracy: 0.9981\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0030 - accuracy: 0.9981\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0021 - accuracy: 0.9981\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0215 - accuracy: 0.9962\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0183 - accuracy: 0.9962\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0416 - accuracy: 0.9944\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0274 - accuracy: 0.9925\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0151 - accuracy: 0.9962\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0144 - accuracy: 0.9962\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0181 - accuracy: 0.9962\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0123 - accuracy: 0.9962\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0051 - accuracy: 0.9962\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0038 - accuracy: 0.9981\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 8.6229e-04 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0019 - accuracy: 0.9981\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0100 - accuracy: 0.9944\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 3.1164e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0138 - accuracy: 0.9962\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0312 - accuracy: 0.9944\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0254 - accuracy: 0.9925\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0092 - accuracy: 0.9962\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0038 - accuracy: 0.9981\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 9.3090e-04 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0081 - accuracy: 0.9981\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0115 - accuracy: 0.9981\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 9.1665e-04 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 4.5362e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 2.3972e-04 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 4.8592e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 4.3888e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 2.2097e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0017 - accuracy: 0.9981\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.8387e-04 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0050 - accuracy: 0.9981\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 8.8575e-04 - accuracy: 1.0000\n",
      "accuracy: 100.00%\n",
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0082 - accuracy: 0.9962\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0062 - accuracy: 0.9981\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 3.7630e-04 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0102 - accuracy: 0.9981\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0066 - accuracy: 0.9981\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 3.5354e-04 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0068 - accuracy: 0.9962\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0148 - accuracy: 0.9962\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0206 - accuracy: 0.9925\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0300 - accuracy: 0.9887\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0127 - accuracy: 0.9944\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0021 - accuracy: 0.9981\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0034 - accuracy: 0.9962\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0069 - accuracy: 0.9981\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0057 - accuracy: 0.9981\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0140 - accuracy: 0.9981\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0190 - accuracy: 0.9962\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0233 - accuracy: 0.9944\n",
      "Epoch 25/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 4.9593e-04 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 4.9003e-04 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 3.2424e-04 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 3.9969e-04 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 3.5003e-04 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.9044e-04 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 2.2568e-04 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 1.4006e-04 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0033 - accuracy: 0.9981\n",
      "Epoch 36/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.4779e-04 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 2.3810e-04 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0054 - accuracy: 0.9981\n",
      "Epoch 42/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.5062e-04 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0015 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 7.0653e-04 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.3217e-04 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 1.5501e-04 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0023 - accuracy: 0.9981\n",
      "Epoch 48/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0172 - accuracy: 0.9962\n",
      "Epoch 49/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 50/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 1.8528e-04 - accuracy: 1.0000\n",
      "accuracy: 100.00%\n",
      "91.28% (+/- 17.44%)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27288/1224745268.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%.2f%% (+/- %.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "if model == 'bicond':\n",
    "    v_num = len(y_train)//10 \n",
    "    _, b3 = divmod(v_num,16)\n",
    "    v_split = (v_num  + (batch_size-b3)) / len(y_train)\n",
    "    history = model2.fit(x_s, y_train, epochs = 50, batch_size = batch_size,validation_split = v_split,  verbose=1)\n",
    "    l = len(x_s_test)\n",
    "    _, balance2 = divmod(l,batch_size)\n",
    "    x_s_test = list(x_s_test)\n",
    "    fill_number = batch_size - balance2\n",
    "    for i in range(fill_number):\n",
    "        x_s_test.append(np.zeros(sentence_maxlen,))\n",
    "        print(len(x_s_test))\n",
    "    x_s_test = np.array(x_s_test)\n",
    "    y_pred = np.round(model2.predict(x_s_test, batch_size = 16))\n",
    "    print(classification_report(y_test, y_pred[:-fill_number], digits=4, labels = [0,1]))\n",
    "else:\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    cvscores = []\n",
    "\n",
    "    for train, val in kfold.split(x_s, classes_[y_train.argmax(1)]):\n",
    "        history = model.fit(x_s[train], y_train[train], epochs = 50, batch_size = batch_size, verbose=1)\n",
    "        scores = model.evaluate(x_s[val], y_train[val], verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        cvscores.append(scores[1] * 100)\n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "\n",
    "    y_pred = np.round(model.predict(x_s_test))\n",
    "    print(classification_report(y_test, y_pred, digits=4, labels = [0,1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca0f84be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.0035927877761423588,\n",
       "  0.008204442448914051,\n",
       "  0.006231089122593403,\n",
       "  0.0003763023123610765,\n",
       "  0.005769252777099609,\n",
       "  0.010172639973461628,\n",
       "  0.0065615298226475716,\n",
       "  0.0003535440191626549,\n",
       "  0.006791478022933006,\n",
       "  0.014845076017081738,\n",
       "  0.02059875801205635,\n",
       "  0.029959039762616158,\n",
       "  0.01273314654827118,\n",
       "  0.0022979143541306257,\n",
       "  0.0021398647222667933,\n",
       "  0.0034309879411011934,\n",
       "  0.006872234400361776,\n",
       "  0.005735727958381176,\n",
       "  0.01399385929107666,\n",
       "  0.0015390785411000252,\n",
       "  0.01899588108062744,\n",
       "  0.0025517733301967382,\n",
       "  0.001054246909916401,\n",
       "  0.023260589689016342,\n",
       "  0.0013967665145173669,\n",
       "  0.0010156385833397508,\n",
       "  0.000495931482873857,\n",
       "  0.0004900253843516111,\n",
       "  0.0003242444072384387,\n",
       "  0.0003996866289526224,\n",
       "  0.0003500333405099809,\n",
       "  0.00019044360669795424,\n",
       "  0.00022568387794308364,\n",
       "  0.0001400576438754797,\n",
       "  0.003306981176137924,\n",
       "  0.00207971828058362,\n",
       "  0.0010317051783204079,\n",
       "  0.00014778516197111458,\n",
       "  0.00023810444690752774,\n",
       "  0.0010248557664453983,\n",
       "  0.005399397574365139,\n",
       "  0.00015062178135849535,\n",
       "  0.0014512683264911175,\n",
       "  0.0007065312820486724,\n",
       "  0.00013216756633482873,\n",
       "  0.00015501324378419667,\n",
       "  0.002300228225067258,\n",
       "  0.017157869413495064,\n",
       "  0.005990974139422178,\n",
       "  0.00018528153304941952],\n",
       " 'accuracy': [1.0,\n",
       "  0.9962406158447266,\n",
       "  0.9981203079223633,\n",
       "  1.0,\n",
       "  0.9981203079223633,\n",
       "  0.9981203079223633,\n",
       "  0.9981203079223633,\n",
       "  1.0,\n",
       "  0.9962406158447266,\n",
       "  0.9962406158447266,\n",
       "  0.9924812316894531,\n",
       "  0.9887217879295349,\n",
       "  0.9943609237670898,\n",
       "  1.0,\n",
       "  0.9981203079223633,\n",
       "  0.9962406158447266,\n",
       "  0.9981203079223633,\n",
       "  0.9981203079223633,\n",
       "  0.9981203079223633,\n",
       "  1.0,\n",
       "  0.9962406158447266,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9943609237670898,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9981203079223633,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9981203079223633,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9981203079223633,\n",
       "  0.9962406158447266,\n",
       "  0.9981203079223633,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc23fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83413cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training and Validation Losses',size = 12)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1599c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f925adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bccbccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2778    0.3261    0.3000        46\n",
      "           1     0.6977    0.4762    0.5660       189\n",
      "\n",
      "   micro avg     0.5738    0.4468    0.5024       235\n",
      "   macro avg     0.4877    0.4011    0.4330       235\n",
      "weighted avg     0.6155    0.4468    0.5140       235\n",
      " samples avg     0.3750    0.3750    0.3750       235\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p/parush/.conda/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/p/parush/.conda/envs/nlp/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bf70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "# cvscores = []\n",
    "\n",
    "# for train, val in kfold.split(x_s, classes_[y_train.argmax(1)]): \n",
    "#     model2.fit(x_s[train], y_train[train], epochs = 5, batch_size = 16, verbose=1)\n",
    "# #     scores = model2.evaluate(x_s[val], y_train[val], verbose=0)\n",
    "# #     print(\"%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))\n",
    "# #     cvscores.append(scores[1] * 100)\n",
    "# # print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_weights = get_embeddings('wikipedia',300,vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3085bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we have to do this?\n",
    "# x_s_ = tf.convert_to_tensor(\n",
    "#     x_s_, dtype=tf.float32, dtype_hint=None, name=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc757d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# j = 16\n",
    "# while j<=640:\n",
    "#     inputs = x_t[i:j]\n",
    "#     lstm = LSTM(128, return_sequences=True, return_state=True)\n",
    "#     whole_seq_output, h_0, c_0 = lstm(inputs,initial_state = [h_0, c_0])\n",
    "#     i += 16\n",
    "#     j += 16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478352ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = Input(batch_shape=(16,1,18))\n",
    "# lstm = LSTM(128, return_sequences=True, return_state=True)\n",
    "# whole_seq_output, h_0, c_0 = lstm(inputs)\n",
    "# model = Model(inputs=inputs, outputs=whole_seq_output)\n",
    "# k = model.predict(x_t[:640])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_memory_state = tf.reshape(\n",
    "#     final_memory_state, (16,1,128), name=None\n",
    "# )\n",
    "\n",
    "# final_carry_state = tf.reshape(\n",
    "#     final_carry_state, (16,1,128), name=None\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e375ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# inputs2 = Input(shape=(1,sentence_maxlen,), name = 'Input')\n",
    "# #embedded_inputs = Embedding(embeddings_weights.shape[0], embeddings_weights.shape[1], weights=[embeddings_weights], name = 'Embedding')(inputs2)\n",
    "# #embedded_inputs2 = Dropout(0.2)(embedded_inputs)\n",
    "# lstm, s1,s2 = LSTM(128,return_sequences=True,return_state=True,dropout=0.3,name = 'lstm')(inputs2, initial_state = i_states)\n",
    "# #lstm = LSTM(128,return_sequences=True,dropout=0.3,name = 'lstm')(inputs2)\n",
    "# flat = Flatten(name = 'Flatten')(lstm)\n",
    "# output = (Dense(3,activation='softmax',name = 'Dense'))(flat)\n",
    "# model2 = Model(inputs=inputs2, outputs=output)\n",
    "# model2.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])    \n",
    "# model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59727728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_t =np.array( [x.reshape(1,18) for x in x_t[:640]])\n",
    "\n",
    "# x_t = tf.convert_to_tensor(\n",
    "#     x_t, dtype=tf.float32, dtype_hint=None, name=None\n",
    "# )\n",
    "\n",
    "# inputs_list = [tf.squeeze(x) for x in\n",
    "#                 tf.split(1, sentence_maxlen, embedded_inputs)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpKernel",
   "language": "python",
   "name": "nlpkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
